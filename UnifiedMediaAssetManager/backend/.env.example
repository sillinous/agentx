# Database Configuration
# For development: sqlite:///./sql_app.db
# For production: postgresql://user:password@host:port/database
DATABASE_URL=sqlite:///./sql_app.db

# JWT Authentication
# IMPORTANT: Change this to a secure random string in production!
# Generate with: python -c "import secrets; print(secrets.token_urlsafe(32))"
JWT_SECRET=dev-secret-change-in-production
JWT_ALGO=HS256

# Development Mode
# Set to true to disable authentication (development only!)
DISABLE_AUTH=false

# CORS Configuration
# Comma-separated list of allowed origins
# For development: http://localhost:3000,http://127.0.0.1:3000
# For production: https://yourdomain.com
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# Media Storage Configuration
# Options: local, s3
MEDIA_STORAGE=local

# S3 Configuration (only needed if MEDIA_STORAGE=s3)
# S3_BUCKET=my-media-bucket
# S3_REGION=us-east-1
# S3_ENDPOINT=https://s3.amazonaws.com (optional, for S3-compatible services)
# S3_PUBLIC_URL_BASE=https://my-cdn.example.com (optional, override public URLs)

# AI Image Generation Provider
# Options: placeholder, http
AI_PROVIDER=placeholder

# HTTP Provider Configuration (only needed if AI_PROVIDER=http)
# AI_PROVIDER_HTTP_URL=https://api.example.com/generate

# AI Provider Retry Configuration
AI_RETRY_ATTEMPTS=3

# Server Configuration (optional)
# HOST=0.0.0.0
# PORT=8000

# Celery Task Queue Configuration
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# AI Agent Configuration
# Anthropic Claude API key for agent-based content generation
# Get your key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# =============================================================================
# Phase 4: Real Provider Integration
# =============================================================================

# Video Generation - Runway ML
# Get your API key from: https://runwayml.com/
# Supports Gen-3 Alpha for text-to-video and image-to-video
RUNWAY_API_KEY=your-runway-api-key-here

# Video Generation - LTX-2 (Alternative/preferred)
# Get your API key from the LTX provider
# Supports text-to-video and image-to-video with high quality
LTX_API_KEY=your-ltx-api-key-here

# Audio - ElevenLabs Text-to-Speech
# Get your API key from: https://elevenlabs.io/
# Supports high-quality voice synthesis with multiple voices
ELEVENLABS_API_KEY=your-elevenlabs-api-key-here

# Audio Transcription - OpenAI Whisper
# Uses OpenAI API for audio transcription
# Get your key from: https://platform.openai.com/
OPENAI_API_KEY=your-openai-api-key-here

# Image Generation - OmniGen2 via Together AI
# Get your API key from: https://together.ai/
# Model: Lightricks/OmniGen2
TOGETHER_API_KEY=your-together-api-key-here

# =============================================================================
# Provider Mode Settings
# =============================================================================
# VIDEO_PROVIDER options:
#   mock    - Use mock provider (development/testing)
#   ltx     - Use LTX-2 provider (requires LTX_API_KEY)
#   runway  - Use Runway ML provider (requires RUNWAY_API_KEY)
#   real    - Auto-select best available (ltx > runway > mock)
VIDEO_PROVIDER=mock

# AUDIO_TTS_PROVIDER options:
#   mock       - Use mock provider (development/testing)
#   elevenlabs - Use ElevenLabs (requires ELEVENLABS_API_KEY)
AUDIO_TTS_PROVIDER=mock

# AUDIO_TRANSCRIBE_PROVIDER options:
#   mock   - Use mock provider (development/testing)
#   whisper - Use OpenAI Whisper (requires OPENAI_API_KEY)
AUDIO_TRANSCRIBE_PROVIDER=mock

# IMAGE_PROVIDER options:
#   mock     - Use mock provider (development/testing)
#   omnigen2 - Use OmniGen2 via Together AI (requires TOGETHER_API_KEY)
#   real     - Auto-select best available (omnigen2 > mock)
IMAGE_PROVIDER=mock

# =============================================================================
# Rate Limiting Configuration
# =============================================================================
# Enable or disable rate limiting (default: true)
RATE_LIMIT_ENABLED=true

# Rate limits are configured per endpoint type:
# - Default endpoints: 60 requests/minute
# - Auth endpoints: 5 requests/minute (brute force protection)
# - AI generation: 10 requests/minute
# - Heavy generation (video/audio): 5 requests/5 minutes

# =============================================================================
# Logging Configuration
# =============================================================================
# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# Log format: json for structured logging (production), leave empty for colored console (dev)
# LOG_FORMAT=json

# Optional log file path for persistent logs
# LOG_FILE=/var/log/umam/app.log

# Enable request logging middleware (default: true)
REQUEST_LOGGING_ENABLED=true

# =============================================================================
# Caching Configuration
# =============================================================================
# Cache backend: memory (default), redis
# CACHE_BACKEND=redis

# Redis URL for caching (if different from Celery broker)
# Uses CELERY_BROKER_URL by default
# REDIS_CACHE_URL=redis://localhost:6379/1
